#!/usr/bin/env python3
"""
Dhamma.kr ìŠ¤í¬ë˜í¼ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥)
"""

import requests
from bs4 import BeautifulSoup
import urllib3
import os
import re

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def scrape_post_content(url):
    """ê°œë³„ ê¸€ ë‚´ìš© í¬ë¡¤ë§"""
    try:
        response = requests.get(url, verify=False, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')

        # ì œëª© ì°¾ê¸°
        title = soup.find('h2')
        title_text = title.get_text(strip=True) if title else "ì œëª© ì—†ìŒ"

        # ë‚´ìš© ì°¾ê¸°
        post_div = soup.find('div', class_='post')
        if post_div:
            paragraphs = post_div.find_all('p')
            content_paragraphs = paragraphs[1:-1] if len(paragraphs) > 2 else paragraphs
            content_text = '\n\n'.join([p.get_text(strip=True) for p in content_paragraphs if p.get_text(strip=True)])
        else:
            content_text = ""

        # ë‚ ì§œ ì°¾ê¸°
        date_span = soup.find('span', class_='date')
        date_text = date_span.get_text(strip=True) if date_span else ""

        return {
            'title': title_text,
            'content': content_text,
            'date': date_text,
            'url': url
        }

    except Exception as e:
        print(f"âš ï¸  í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None

def save_as_text(post_data, output_dir):
    """ê¸€ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥"""
    if not post_data:
        return False

    try:
        # íŒŒì¼ëª… ìƒì„±
        safe_title = re.sub(r'[^\w\s-]', '', post_data['title'])[:50]
        filename = f"{safe_title}.txt"
        filepath = os.path.join(output_dir, filename)

        # í…ìŠ¤íŠ¸ íŒŒì¼ ì‘ì„±
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"ì œëª©: {post_data['title']}\n")
            f.write(f"ë‚ ì§œ: {post_data['date']}\n")
            f.write(f"URL: {post_data['url']}\n")
            f.write("\n" + "="*80 + "\n\n")
            f.write(post_data['content'])

        print(f"âœ… í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
        return True

    except Exception as e:
        print(f"âš ï¸  íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    output_dir = "/Users/jinseulpark/Desktop/github/jsks_app/scraper/texts"
    os.makedirs(output_dir, exist_ok=True)

    # í…ŒìŠ¤íŠ¸ URL
    test_url = "http://www.dhamma.kr/wp/?p=17762"

    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘: 1ê°œ ê¸€ í¬ë¡¤ë§ ë° í…ìŠ¤íŠ¸ ì €ì¥\n")
    print(f"URL: {test_url}\n")

    post_data = scrape_post_content(test_url)

    if post_data:
        print(f"ì œëª©: {post_data['title']}")
        print(f"ë‚ ì§œ: {post_data['date']}")
        print(f"ë‚´ìš© ê¸¸ì´: {len(post_data['content'])} ì")
        print(f"\në‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n{post_data['content'][:300]}...\n")

        save_as_text(post_data, output_dir)
        print("\nâœ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨")
